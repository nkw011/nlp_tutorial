{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HcLf4iJEvwu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load pretrained instances with an AutoClass\n",
    "\n",
    "※ 이 글의 원문은 [이 곳](https://huggingface.co/docs/transformers/autoclass_tutorial)에서 확인할 수 있습니다. (모든 글의 내용을 포함하지 않으며 새롭게 구성한 내용도 포함되어 있습니다.)\n",
    "\n",
    "🤗 Transformers는 [Model Hub](https://huggingface.co/models)에 등록된 수많은 pretrained model을 간편하게 사용할 수 있도록 [AutoClass](https://huggingface.co/docs/transformers/v4.21.2/en/model_doc/auto#auto-classes)를 제공합니다.\n",
    "* from_pretrained 메소드를 이용해서 손쉽게 model과 tokenizer을 load할 수 있게 해줍니다.\n",
    "\n",
    "이번 시간에는 AutoClass를 이용해서 tokenizer, model을 load하는 방법을 배워보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11650,
     "status": "ok",
     "timestamp": 1661315460353,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "Te2at74aHbJZ",
    "outputId": "aac0410a-a1c7-4768-ade3-b2f1be77e954",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOwKGKDfGvvL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AutoTokenizer\n",
    "\n",
    "AutoTokenizer를 이용해서 학습에 필요한 tokenizer를 손쉽게 load할 수 있습니다.\n",
    "\n",
    "AutoTokenizer.from_pretrained()를 이용해서 [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)의 tokenizer를 불러옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6SMg8kUrEULv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PVZTCDUzHwUF",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALsGaQ6eIDJZ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "bert-base-multilingual-cased tokenizer를 사용하기위해 필요한 config, vocab 등을 다운로드 받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 461,
     "status": "ok",
     "timestamp": 1661315676213,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "0a8HEiwzH31a",
    "outputId": "2dc5c12c-0f29-4c9c-bfea-c47afd9518cb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-multilingual-cased', vocab_size=119547, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a1UVFcHIoXI",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tokenizer.vocab을 이용하여 vocab을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1661315730466,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "zx7YDYbvIUNI",
    "outputId": "5adfc109-7873-4e76-9978-3c2b6914e06e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##či': 15515,\n",
       " 'bədii': 94387,\n",
       " 'sudaro': 62386,\n",
       " 'früheren': 42936,\n",
       " 'Freiburg': 29283,\n",
       " '##biendo': 57369,\n",
       " 'junction': 49806,\n",
       " 'فرض': 95311,\n",
       " 'SQL': 60793,\n",
       " '##术': 114244,\n",
       " 'aC': 28705,\n",
       " '##ತ್ತದೆ': 65957,\n",
       " '##jord': 42515,\n",
       " 'écrits': 67685,\n",
       " 'emperador': 24244,\n",
       " '##olat': 99447,\n",
       " '##rtar': 95941,\n",
       " '##wege': 40529,\n",
       " '##pel': 17703,\n",
       " '##능하다': 96535,\n",
       " '##erbit': 97725,\n",
       " 'платформа': 70603,\n",
       " '##tations': 82795,\n",
       " '##mentul': 89300,\n",
       " '##cilla': 92952,\n",
       " '##墳': 112919,\n",
       " 'saat': 16214,\n",
       " '##פכה': 68207,\n",
       " 'seo': 27857,\n",
       " '##jení': 76569,\n",
       " '##aí': 43002,\n",
       " '##snici': 99438,\n",
       " 'Hélène': 50168,\n",
       " '##gama': 81842,\n",
       " 'kritika': 100873,\n",
       " 'provenienti': 54445,\n",
       " 'Roskilde': 81147,\n",
       " '瑶': 5559,\n",
       " 'mortal': 97952,\n",
       " 'descrita': 35708,\n",
       " 'Сост': 80947,\n",
       " 'Noche': 109589,\n",
       " '##鲨': 118453,\n",
       " 'tím': 31200,\n",
       " '##ipa': 60287,\n",
       " 'العمر': 31574,\n",
       " '##迥': 117472,\n",
       " '##cupen': 72572,\n",
       " '##ンク': 57619,\n",
       " 'Telecom': 79642,\n",
       " '##posal': 101177,\n",
       " '醣': 7891,\n",
       " 'الكويت': 62329,\n",
       " 'strike': 37456,\n",
       " 'Dallas': 20003,\n",
       " 'manj': 98506,\n",
       " '小': 3459,\n",
       " '##दल': 99989,\n",
       " 'Lig': 40056,\n",
       " 'footballeur': 45137,\n",
       " 'ను': 55753,\n",
       " '##μερα': 102850,\n",
       " 'lb': 23989,\n",
       " '##ریا': 92442,\n",
       " 'bispo': 58890,\n",
       " 'fundo': 80976,\n",
       " '##ري': 21034,\n",
       " 'Beispiele': 73424,\n",
       " 'януари': 39079,\n",
       " '##pido': 101642,\n",
       " '##skop': 67959,\n",
       " '##руна': 109309,\n",
       " '##ument': 58079,\n",
       " '##steries': 58393,\n",
       " '##אחרים': 70366,\n",
       " 'তারিখ': 17325,\n",
       " 'Triều': 56476,\n",
       " '焜': 5317,\n",
       " 'artistico': 80435,\n",
       " '##ταση': 85821,\n",
       " '##gruppen': 39085,\n",
       " '##icae': 84580,\n",
       " '##ಕವಾಗಿ': 87463,\n",
       " 'континентан': 23221,\n",
       " '1767': 29056,\n",
       " 'энциклопедический': 96742,\n",
       " 'Энсиклопедияи': 102837,\n",
       " 'գ': 670,\n",
       " 'Polski': 16262,\n",
       " 'Wight': 78725,\n",
       " '##heit': 15543,\n",
       " '266': 28477,\n",
       " 'продюсер': 59589,\n",
       " '传': 2230,\n",
       " '##лу': 16111,\n",
       " 'откриен': 77690,\n",
       " 'users': 32095,\n",
       " '물': 9299,\n",
       " '琇': 5516,\n",
       " '##lveren': 88917,\n",
       " 'उनकी': 38159,\n",
       " 'cao': 15341,\n",
       " '##قال': 44123,\n",
       " '##cale': 45330,\n",
       " 'ֆեդերալ': 58413,\n",
       " 'opět': 40948,\n",
       " 'ser': 10493,\n",
       " 'delà': 52063,\n",
       " '##בלה': 54579,\n",
       " 'декабре': 39423,\n",
       " 'Llundain': 104224,\n",
       " '##мбар': 68217,\n",
       " '끊': 8972,\n",
       " 'famiglia': 15567,\n",
       " 'jewografik': 52129,\n",
       " '##οντας': 63972,\n",
       " '##出': 112293,\n",
       " 'Blant': 79945,\n",
       " 'బ్యాంకు': 23934,\n",
       " 'Poznań': 39926,\n",
       " 'defensa': 24081,\n",
       " 'исторический': 96547,\n",
       " '##گاههای': 92641,\n",
       " '##粱': 115923,\n",
       " 'Sokol': 104869,\n",
       " 'Cultura': 22812,\n",
       " 'Civic': 64617,\n",
       " 'ворота': 62516,\n",
       " 'roba': 96684,\n",
       " '##fiziert': 91170,\n",
       " 'técnico': 37561,\n",
       " 'усіх': 44599,\n",
       " '粒': 6146,\n",
       " '乖': 2129,\n",
       " 'pseudonym': 94734,\n",
       " 'institutions': 24671,\n",
       " '##monė': 100694,\n",
       " 'αριθμός': 79048,\n",
       " 'importance': 21912,\n",
       " 'ऐसे': 70648,\n",
       " 'Chrysomelidae': 28551,\n",
       " 'zdobyła': 64293,\n",
       " 'postaje': 39328,\n",
       " 'MX': 68646,\n",
       " '##会': 111992,\n",
       " 'celá': 110220,\n",
       " 'ৌ': 990,\n",
       " 'Inga': 10958,\n",
       " '##tau': 68330,\n",
       " '##kian': 79189,\n",
       " '##্রিয়': 70529,\n",
       " '새로운': 39773,\n",
       " 'іноді': 71059,\n",
       " 'เกิดเมื่อวันที่': 91743,\n",
       " 'VHS': 39915,\n",
       " 'ویکیپیڈیا': 16492,\n",
       " 'Puente': 55230,\n",
       " '##ільного': 99348,\n",
       " 'أنثى': 73531,\n",
       " '##্যান': 110742,\n",
       " '##orchester': 91228,\n",
       " '##尴': 113239,\n",
       " 'Ingenieur': 85748,\n",
       " 'véritable': 47888,\n",
       " '##dhi': 46689,\n",
       " '##사가': 49636,\n",
       " 'permite': 22889,\n",
       " 'pp': 11309,\n",
       " '皆': 5719,\n",
       " '볼': 9359,\n",
       " 'რომლის': 48904,\n",
       " '獻': 5472,\n",
       " 'informação': 80773,\n",
       " 'acest': 27007,\n",
       " '##ზა': 57609,\n",
       " 'Planets': 42501,\n",
       " '##ρια': 28280,\n",
       " 'цуьнан': 35292,\n",
       " '##梦': 114380,\n",
       " '##浮': 114769,\n",
       " '##МФ': 98916,\n",
       " '##ązania': 102814,\n",
       " '##Δ': 111034,\n",
       " 'Everything': 34864,\n",
       " 'Zhu': 50311,\n",
       " '##್ದು': 66519,\n",
       " '##ריות': 70078,\n",
       " '##yrtare': 97993,\n",
       " '规': 7158,\n",
       " '##為': 115053,\n",
       " 'combate': 26628,\n",
       " '##hi': 11924,\n",
       " 'цел': 40951,\n",
       " '##bec': 79478,\n",
       " 'apmēram': 96490,\n",
       " 'അഥവാ': 100862,\n",
       " '##ares': 27458,\n",
       " 'Goodwin': 95985,\n",
       " '##вості': 65094,\n",
       " 'iklimi': 36157,\n",
       " 'stierf': 71364,\n",
       " 'Europaea': 35662,\n",
       " '##usse': 33181,\n",
       " '##ором': 52735,\n",
       " 'lenguaje': 65621,\n",
       " 'मंदिर': 43799,\n",
       " '##hmann': 76912,\n",
       " 'buried': 26768,\n",
       " '1659': 43135,\n",
       " 'місті': 24242,\n",
       " 'теме': 57819,\n",
       " 'достижения': 78741,\n",
       " 'ივლისი': 89050,\n",
       " 'Ralf': 63424,\n",
       " 'embora': 33697,\n",
       " '尽': 3480,\n",
       " 'siji': 51213,\n",
       " 'droga': 42682,\n",
       " '##ает': 25471,\n",
       " '岔': 3512,\n",
       " '##냉': 118727,\n",
       " 'estadunidense': 51125,\n",
       " 'tomēr': 84972,\n",
       " 'clara': 49055,\n",
       " '褒': 7124,\n",
       " 'cerámica': 101547,\n",
       " '##奶': 113003,\n",
       " 'construción': 103259,\n",
       " '##haltung': 40192,\n",
       " '##עביר': 71887,\n",
       " '##ეთში': 57958,\n",
       " 'Spectrum': 65733,\n",
       " '铁': 8068,\n",
       " '鴉': 8715,\n",
       " '疣': 5654,\n",
       " '##руг': 75624,\n",
       " 'nuevo': 15249,\n",
       " '##沢': 114684,\n",
       " '##arius': 89792,\n",
       " 'osaa': 100065,\n",
       " 'средата': 86164,\n",
       " '##agg': 99274,\n",
       " 'النادي': 79176,\n",
       " '##കൻ': 79843,\n",
       " 'Officer': 25467,\n",
       " 'áreas': 23571,\n",
       " 'Сепак': 98567,\n",
       " 'mestre': 41322,\n",
       " '##餉': 118235,\n",
       " '尔': 3461,\n",
       " 'niini': 23982,\n",
       " '##жной': 37803,\n",
       " '##حداث': 108325,\n",
       " 'મ': 1106,\n",
       " '##áján': 106323,\n",
       " 'Парижа': 32559,\n",
       " '##夙': 112956,\n",
       " 'която': 18818,\n",
       " '##آں': 96692,\n",
       " '##็': 111437,\n",
       " 'Шӯрои': 80875,\n",
       " 'hatramin': 74220,\n",
       " 'күп': 50504,\n",
       " 'أقل': 54676,\n",
       " 'complète': 66026,\n",
       " '##doria': 101233,\n",
       " 'Новиот': 76613,\n",
       " '##GM': 66025,\n",
       " '##dée': 87321,\n",
       " '##ندگی': 54759,\n",
       " 'Burning': 49594,\n",
       " 'аркылуу': 71394,\n",
       " 'kN': 72174,\n",
       " '##року': 109089,\n",
       " 'Nove': 103226,\n",
       " 'অতার': 21908,\n",
       " 'Bassi': 59842,\n",
       " 'utilitzat': 85659,\n",
       " '##ôr': 42701,\n",
       " 'chargée': 91628,\n",
       " 'Washington': 11586,\n",
       " 'trí': 20098,\n",
       " 'పోస్టాఫీసు': 24790,\n",
       " 'Squad': 53150,\n",
       " '##్రం': 63437,\n",
       " '##ano': 12301,\n",
       " 'Максим': 55883,\n",
       " '##tisk': 32251,\n",
       " '##ënë': 90724,\n",
       " '810': 49357,\n",
       " '##ободно': 95165,\n",
       " 'spośród': 106698,\n",
       " '過': 7758,\n",
       " 'znamená': 58194,\n",
       " '##isa': 19403,\n",
       " 'guerre': 14158,\n",
       " 'ming': 58102,\n",
       " '##desi': 94228,\n",
       " 'round': 13569,\n",
       " 'meaning': 21157,\n",
       " 'Nachbargemeinden': 71311,\n",
       " '兌': 2434,\n",
       " 'ostrova': 95552,\n",
       " '##已': 113358,\n",
       " '##ợn': 72633,\n",
       " 'MY': 94592,\n",
       " 'neveu': 99240,\n",
       " '##azi': 28059,\n",
       " '##건': 71439,\n",
       " 'Native': 26061,\n",
       " 'gihulagway': 28153,\n",
       " '##μό': 47851,\n",
       " '##илософ': 105043,\n",
       " 'ể': 1665,\n",
       " 'belonging': 54188,\n",
       " '##freien': 74629,\n",
       " 'euskal': 70936,\n",
       " 'Transvaal': 78463,\n",
       " '##puestu': 100835,\n",
       " 'cars': 24602,\n",
       " 'القرآن': 56306,\n",
       " '২০১৫': 31784,\n",
       " 'ларарца': 36298,\n",
       " 'fehiben': 62974,\n",
       " 'JR': 18538,\n",
       " 'giri': 79979,\n",
       " 'حافظ': 98616,\n",
       " 'עברו': 108194,\n",
       " '##萬': 116586,\n",
       " '##מדינות': 72424,\n",
       " 'преминава': 81757,\n",
       " '徊': 3768,\n",
       " '1871': 13511,\n",
       " '##ņa': 26405,\n",
       " '##gabe': 30337,\n",
       " 'ὶ': 1714,\n",
       " '伞': 2228,\n",
       " '##嵌': 113326,\n",
       " '##బడుతుంది': 110473,\n",
       " 'السكنية': 74535,\n",
       " 'februārī': 89467,\n",
       " '##麵': 118555,\n",
       " '##ville': 12043,\n",
       " 'tiện': 87737,\n",
       " 'powodu': 33672,\n",
       " 'أول': 20582,\n",
       " 'armé': 70183,\n",
       " '##gimento': 76245,\n",
       " '##inko': 107113,\n",
       " 'seriál': 79684,\n",
       " '椙': 4652,\n",
       " '##undu': 87316,\n",
       " 'Ямал': 77043,\n",
       " '##hyl': 78731,\n",
       " 'Иоанна': 91151,\n",
       " 'komme': 35796,\n",
       " 'сначала': 51174,\n",
       " 'Abridgment': 80989,\n",
       " 'heure': 47034,\n",
       " 'जुजुतयेगु': 98622,\n",
       " 'currency': 83759,\n",
       " 'נבנה': 109346,\n",
       " 'জুন': 25017,\n",
       " 'soixante': 108512,\n",
       " '##॰': 111217,\n",
       " 'Singles': 20112,\n",
       " '하나이다': 86736,\n",
       " '##ुल': 52736,\n",
       " '##yki': 35696,\n",
       " 'животных': 49800,\n",
       " '瓢': 5586,\n",
       " '##press': 43379,\n",
       " '##ånden': 104680,\n",
       " 'crossing': 41031,\n",
       " '褻': 7131,\n",
       " '##ástico': 70993,\n",
       " 'Στις': 27666,\n",
       " 'Tomo': 52521,\n",
       " 'Guadalajara': 39346,\n",
       " 'kemungkinan': 83918,\n",
       " 'obyekt': 77997,\n",
       " 'সকল': 87664,\n",
       " '##isso': 98917,\n",
       " 'costruzione': 26057,\n",
       " 'hän': 11960,\n",
       " '##ovým': 61147,\n",
       " 'bază': 100105,\n",
       " 'magnitud': 65319,\n",
       " '##句': 112514,\n",
       " '##芭': 116454,\n",
       " 'ช': 1402,\n",
       " 'Akademi': 46902,\n",
       " 'Namens': 97692,\n",
       " '##唇': 112644,\n",
       " '##ńska': 26461,\n",
       " '##ink': 39717,\n",
       " 'Diptera': 12203,\n",
       " '醒': 7887,\n",
       " 'décrit': 42408,\n",
       " '##מקרים': 67608,\n",
       " '##үндүк': 73754,\n",
       " 'herceg': 62646,\n",
       " '##дства': 58741,\n",
       " '##walt': 57710,\n",
       " '李': 4489,\n",
       " '臀': 6608,\n",
       " 'prevention': 94469,\n",
       " '##iria': 108285,\n",
       " '##rts': 26215,\n",
       " '倍': 2334,\n",
       " '##ttamente': 94918,\n",
       " 'Советская': 34631,\n",
       " '##倾': 112122,\n",
       " '##raucht': 108426,\n",
       " 'Prix': 12835,\n",
       " '1016': 18125,\n",
       " 'měl': 26881,\n",
       " '##ního': 24247,\n",
       " '##ulla': 63486,\n",
       " 'قدره': 74890,\n",
       " '##מקומות': 74913,\n",
       " '##айк': 99189,\n",
       " '##贡': 117242,\n",
       " 'Eileen': 97274,\n",
       " '##dza': 29958,\n",
       " 'nếu': 41800,\n",
       " 'Igor': 28802,\n",
       " '##حية': 40369,\n",
       " 'pesos': 68019,\n",
       " '僻': 2407,\n",
       " '琿': 5537,\n",
       " 'Denmark': 25854,\n",
       " 'hampir': 44371,\n",
       " 'ઇ': 1072,\n",
       " '##बा': 57381,\n",
       " 'ॄ': 908,\n",
       " '谓': 7374,\n",
       " 'Fa': 44271,\n",
       " 'tercer': 21927,\n",
       " 'motora': 91660,\n",
       " '##mischen': 105874,\n",
       " 'sotto': 16033,\n",
       " 'sierpniu': 65152,\n",
       " '##йд': 74346,\n",
       " 'Isa': 56787,\n",
       " 'participent': 96280,\n",
       " '##ier': 11709,\n",
       " '##হিনীর': 93659,\n",
       " '##vár': 67733,\n",
       " 'phù': 79492,\n",
       " 'nt': 86459,\n",
       " 'Cardinal': 47610,\n",
       " 'Geology': 103095,\n",
       " '##צרים': 51239,\n",
       " 'لاحق': 110462,\n",
       " '##幢': 113403,\n",
       " 'formas': 23189,\n",
       " 'Morales': 37397,\n",
       " 'сторона': 106348,\n",
       " '飢': 8459,\n",
       " 'Blair': 34931,\n",
       " 'considère': 63441,\n",
       " 'ستمبر': 104556,\n",
       " '##יקים': 81374,\n",
       " '##もの': 28073,\n",
       " '##nky': 54206,\n",
       " '##bo': 11790,\n",
       " 'Boulogne': 52829,\n",
       " 'drafted': 55746,\n",
       " 'পর': 29740,\n",
       " '##міі': 109840,\n",
       " '440': 24653,\n",
       " '##кай': 34180,\n",
       " 'highway': 31729,\n",
       " '##יפה': 59820,\n",
       " 'মার্কিন': 45418,\n",
       " '##nın': 13153,\n",
       " 'Als': 11966,\n",
       " '##inkel': 106996,\n",
       " 'ат': 72701,\n",
       " 'protéger': 68624,\n",
       " '##oit': 84055,\n",
       " 'fases': 56815,\n",
       " 'Diario': 48135,\n",
       " '##ال': 13154,\n",
       " 'fünften': 76103,\n",
       " 'naast': 41964,\n",
       " 'afkomstig': 52557,\n",
       " 'radiación': 103342,\n",
       " 'framework': 54387,\n",
       " 'internacionais': 70729,\n",
       " '##zov': 74883,\n",
       " '##chor': 50197,\n",
       " 'assembly': 38946,\n",
       " 'birlikte': 22144,\n",
       " '##landi': 41805,\n",
       " 'utilizan': 62024,\n",
       " '##larni': 79707,\n",
       " '대': 9069,\n",
       " '毋': 4833,\n",
       " 'Ένωση': 102569,\n",
       " '##alaisten': 104684,\n",
       " 'Blizzard': 110540,\n",
       " 'أكثر': 17597,\n",
       " 'מ': 737,\n",
       " '把': 4033,\n",
       " 'mwyn': 50620,\n",
       " 'ก': 1395,\n",
       " 'Alfonso': 19780,\n",
       " 'before': 11360,\n",
       " '##旦': 114115,\n",
       " 'earning': 56981,\n",
       " '##твует': 64260,\n",
       " '##確': 115642,\n",
       " '탑': 9850,\n",
       " 'odbyły': 82684,\n",
       " '##тения': 99926,\n",
       " 'naturale': 37220,\n",
       " '##バス': 46468,\n",
       " '##ರೂ': 72191,\n",
       " 'Michael': 10631,\n",
       " '##borg': 18026,\n",
       " 'ανέλαβε': 82654,\n",
       " 'ottobre': 15890,\n",
       " '雒': 8280,\n",
       " 'anvet': 58309,\n",
       " '##cend': 89387,\n",
       " 'passeggeri': 99312,\n",
       " 'facto': 26431,\n",
       " '##uk': 13013,\n",
       " '##nsä': 37746,\n",
       " 'uns': 15826,\n",
       " 'cantata': 79450,\n",
       " '##ície': 85278,\n",
       " 'выніку': 71539,\n",
       " '##уха': 88081,\n",
       " '##כתב': 36270,\n",
       " '近': 7697,\n",
       " 'artística': 41427,\n",
       " '畅': 5619,\n",
       " '凧': 2517,\n",
       " 'year': 10924,\n",
       " '##cepción': 51609,\n",
       " '##вол': 110687,\n",
       " '##ullit': 60219,\n",
       " '谅': 7365,\n",
       " '勛': 2626,\n",
       " 'contra': 11473,\n",
       " '1927': 11442,\n",
       " 'pH': 30211,\n",
       " '##에게': 26212,\n",
       " 'Attila': 42343,\n",
       " '##zycznej': 74517,\n",
       " '##offer': 97329,\n",
       " '##徭': 113550,\n",
       " 'Heath': 42676,\n",
       " '##iated': 89771,\n",
       " '##вар': 44146,\n",
       " '##讐': 117059,\n",
       " 'Freddie': 41323,\n",
       " '秦': 5960,\n",
       " 'FishBase': 14968,\n",
       " 'ઓફ': 56515,\n",
       " 'Ausdruck': 65046,\n",
       " '##تبة': 95782,\n",
       " '##środek': 78190,\n",
       " '佬': 2268,\n",
       " 'một': 10417,\n",
       " 'enfin': 37063,\n",
       " 'generazione': 90715,\n",
       " 'Capitán': 69797,\n",
       " 'лице': 75599,\n",
       " 'cache': 62070,\n",
       " 'als': 10223,\n",
       " 'denominato': 107614,\n",
       " '##upu': 90571,\n",
       " 'Italien': 19219,\n",
       " '##푼': 119406,\n",
       " 'júla': 104024,\n",
       " '##ório': 31098,\n",
       " '##wley': 62381,\n",
       " '##ml': 63308,\n",
       " 'Chem': 26609,\n",
       " 'lodí': 87391,\n",
       " '##っていた': 59835,\n",
       " 'ɑ': 388,\n",
       " '##adta': 63501,\n",
       " 'чем': 18658,\n",
       " 'aceeași': 91180,\n",
       " '艮': 6666,\n",
       " 'CW': 63216,\n",
       " 'kilometriä': 41301,\n",
       " '##увала': 44497,\n",
       " '##遂': 117518,\n",
       " 'Chevillotte': 49315,\n",
       " 'Celtic': 30948,\n",
       " '##chi': 12806,\n",
       " '##iidae': 23256,\n",
       " 'películes': 91922,\n",
       " 'siguen': 79154,\n",
       " 'ワ': 2061,\n",
       " 'expansion': 24837,\n",
       " '##笺': 115831,\n",
       " 'Ō': 337,\n",
       " 'റ': 1360,\n",
       " 'sterkt': 67797,\n",
       " 'Coro': 89159,\n",
       " '##ager': 37247,\n",
       " '##遵': 117543,\n",
       " 'dadurch': 34133,\n",
       " 'الشركات': 105643,\n",
       " '##ních': 20760,\n",
       " 'portanto': 71711,\n",
       " 'language': 13702,\n",
       " '„': 1725,\n",
       " '黜': 8808,\n",
       " 'når': 19138,\n",
       " '1657': 43840,\n",
       " 'Ramsay': 73220,\n",
       " 'Cameroun': 92205,\n",
       " '##ḑ': 111550,\n",
       " '##ningar': 23577,\n",
       " 'guest': 26959,\n",
       " '##િત': 27842,\n",
       " '##ĕш': 90713,\n",
       " '##蕙': 116653,\n",
       " 'behov': 88427,\n",
       " '##ugati': 85844,\n",
       " 'shield': 88939,\n",
       " 'Ground': 33133,\n",
       " 'Marco': 14160,\n",
       " '##tí': 18619,\n",
       " 'públicu': 98125,\n",
       " '##侏': 112048,\n",
       " '##ире': 87052,\n",
       " 'ყ': 1587,\n",
       " '583': 49134,\n",
       " '2546': 86087,\n",
       " 'dirigente': 59606,\n",
       " 'Nikolai': 32707,\n",
       " 'пачхьалкхан': 73753,\n",
       " 'succeeded': 28126,\n",
       " '##nen': 11216,\n",
       " 'estavam': 41719,\n",
       " '##యం': 20123,\n",
       " 'quantité': 71726,\n",
       " '녔': 9020,\n",
       " 'reliable': 103581,\n",
       " 'Ọ': 1670,\n",
       " '##дского': 78546,\n",
       " 'Raquel': 93896,\n",
       " 'hektar': 33009,\n",
       " '鞍': 8348,\n",
       " 'situazione': 39498,\n",
       " '##νταν': 61253,\n",
       " '旻': 4359,\n",
       " '##rsti': 88241,\n",
       " 'Império': 45640,\n",
       " '##suke': 40096,\n",
       " '##сор': 108493,\n",
       " 'شہروں': 88790,\n",
       " '##يف': 20884,\n",
       " 'gjin': 76435,\n",
       " 'Salt': 29243,\n",
       " '##ctores': 98641,\n",
       " '07an': 109148,\n",
       " '##ёрного': 109217,\n",
       " 'клубе': 64909,\n",
       " '寂': 3414,\n",
       " 'Ceir': 71113,\n",
       " 'miglior': 30303,\n",
       " '##чул': 52375,\n",
       " 'beschikbaar': 99285,\n",
       " '##يين': 22328,\n",
       " '##ોમાં': 85976,\n",
       " 'rubber': 92724,\n",
       " 'догӀанаш': 70207,\n",
       " '##фа': 19595,\n",
       " '##onna': 76667,\n",
       " 'Mandarin': 89033,\n",
       " 'се': 10277,\n",
       " '##vinen': 98613,\n",
       " 'Patriots': 66523,\n",
       " 'secretario': 59119,\n",
       " '##rela': 50619,\n",
       " 'menghadapi': 102677,\n",
       " '##dlem': 78957,\n",
       " 'moda': 38231,\n",
       " 'Ņ': 332,\n",
       " 'tone': 43619,\n",
       " '##꿀': 118696,\n",
       " '##垂': 112831,\n",
       " 'visuomenės': 69245,\n",
       " '##图': 112781,\n",
       " '##raphy': 81503,\n",
       " 'vezes': 20971,\n",
       " '##len': 11608,\n",
       " 'igen': 24136,\n",
       " 'Інфармацыя': 56994,\n",
       " '##luas': 94490,\n",
       " 'planetoida': 79244,\n",
       " 'Norway': 22582,\n",
       " 'Heimat': 37946,\n",
       " 'общината': 80219,\n",
       " '亦': 2167,\n",
       " 'BMW': 23998,\n",
       " 'Jungen': 77205,\n",
       " '##race': 47288,\n",
       " '것을': 21371,\n",
       " '虏': 6942,\n",
       " 'अप्वया': 58188,\n",
       " 'dramatic': 60156,\n",
       " '##áez': 84565,\n",
       " '##ледж': 87469,\n",
       " 'Čech': 107377,\n",
       " '##tiae': 110731,\n",
       " '##štvo': 59671,\n",
       " 'defeat': 24800,\n",
       " '橘': 4739,\n",
       " '524': 47189,\n",
       " '##тардың': 62620,\n",
       " '##names': 84898,\n",
       " 'sabit': 38943,\n",
       " 'ἶ': 1706,\n",
       " '##žen': 34306,\n",
       " 'گے': 110812,\n",
       " '##酗': 117631,\n",
       " '##genen': 85980,\n",
       " 'atac': 58586,\n",
       " '##жби': 106724,\n",
       " '프랑스의': 105787,\n",
       " '##ஊ': 111298,\n",
       " 'Estrella': 73815,\n",
       " '##ത്തിയ': 91418,\n",
       " 'فترة': 36347,\n",
       " '역': 9566,\n",
       " '##lje': 21235,\n",
       " 'リ': 2057,\n",
       " '##мон': 38902,\n",
       " '##羞': 116186,\n",
       " 'városban': 99685,\n",
       " 'физико': 102733,\n",
       " '가': 8843,\n",
       " 'కంటే': 22539,\n",
       " '##wahl': 39538,\n",
       " 'православной': 85514,\n",
       " 'الأصول': 87719,\n",
       " '##бива': 98208,\n",
       " 'Ghose': 110467,\n",
       " '##iskt': 59271,\n",
       " 'dibuka': 72986,\n",
       " 'behulp': 98072,\n",
       " 'Victoire': 100078,\n",
       " '##zky': 46575,\n",
       " 'noordelijke': 105685,\n",
       " '##stió': 67296,\n",
       " 'hulka': 103206,\n",
       " 'ಮಾಡಿ': 104498,\n",
       " '##ئلة': 90080,\n",
       " 'Հանրապետության': 52771,\n",
       " 'рата': 31024,\n",
       " '##dragen': 63702,\n",
       " 'Alcalá': 69540,\n",
       " 'hablar': 85941,\n",
       " '##ədə': 38469,\n",
       " '##লো': 105864,\n",
       " 'livskraftig': 72072,\n",
       " '冬': 2490,\n",
       " '触': 7166,\n",
       " 'تھا': 19249,\n",
       " '##mau': 89793,\n",
       " 'כסף': 63225,\n",
       " '##スを': 98312,\n",
       " '##芎': 116445,\n",
       " 'rien': 37575,\n",
       " 'ngoài': 25331,\n",
       " 'pomiędzy': 29292,\n",
       " '##жер': 73739,\n",
       " 'kilómetros': 29819,\n",
       " '垠': 3075,\n",
       " 'życie': 49934,\n",
       " '[unused34]': 34,\n",
       " '鮨': 8635,\n",
       " 'stil': 28510,\n",
       " 'closure': 69177,\n",
       " 'adulte': 96346,\n",
       " 'Сад': 103629,\n",
       " '##enä': 84483,\n",
       " 'karijeru': 100734,\n",
       " '##lok': 84321,\n",
       " '##၌': 111509,\n",
       " '##ņas': 38088,\n",
       " '##egi': 56857,\n",
       " '##pter': 38384,\n",
       " 'русской': 39168,\n",
       " 'Inhalt': 103264,\n",
       " '##搶': 113971,\n",
       " '##buk': 58074,\n",
       " 'atualmente': 38991,\n",
       " '申': 5613,\n",
       " '##гой': 94933,\n",
       " '##нші': 68177,\n",
       " 'domów': 101204,\n",
       " '##దు': 41711,\n",
       " '২২': 46550,\n",
       " 'северной': 63070,\n",
       " 'mesin': 47285,\n",
       " '##ографии': 93117,\n",
       " '响': 2861,\n",
       " '##hada': 67268,\n",
       " '##ённый': 71233,\n",
       " 'Camilo': 94384,\n",
       " 'azione': 38047,\n",
       " 'Ideas': 100426,\n",
       " '##xarı': 106945,\n",
       " '##処': 112282,\n",
       " 'október': 23343,\n",
       " '##ciem': 64946,\n",
       " 'Coleman': 39443,\n",
       " '##תות': 109672,\n",
       " '##鬧': 118377,\n",
       " 'cal': 25923,\n",
       " 'menší': 65175,\n",
       " '๐': 1462,\n",
       " 'Andrea': 16101,\n",
       " '##כול': 62577,\n",
       " 'делает': 83389,\n",
       " '##chidae': 101050,\n",
       " 'Vaughn': 102117,\n",
       " 'Oeste': 36392,\n",
       " '谐': 7372,\n",
       " 'Тұрғындарының': 48926,\n",
       " 'mpikambana': 33275,\n",
       " 'hamar': 96474,\n",
       " 'moderní': 103671,\n",
       " '臚': 6615,\n",
       " '##jam': 36887,\n",
       " '##되어': 16855,\n",
       " 'HK': 33150,\n",
       " 'Textus': 90365,\n",
       " '##ặt': 77381,\n",
       " 'ะ': 1439,\n",
       " '##ದ್ಧ': 90254,\n",
       " 'giovani': 44317,\n",
       " 'Gori': 99378,\n",
       " 'suma': 44366,\n",
       " '##āts': 45297,\n",
       " '##術': 116837,\n",
       " '1993년': 68005,\n",
       " 'Радянського': 94448,\n",
       " '##حافظ': 98427,\n",
       " '##hera': 73995,\n",
       " '62': 12066,\n",
       " 'từng': 26258,\n",
       " '1303': 91525,\n",
       " 'similaire': 84292,\n",
       " 'tunnettu': 74166,\n",
       " 'Basílica': 106481,\n",
       " '##畔': 115390,\n",
       " 'Pauli': 54583,\n",
       " 'Quartal': 104640,\n",
       " '##meno': 55762,\n",
       " '凭': 2519,\n",
       " '##ndor': 57261,\n",
       " 'presenten': 84080,\n",
       " 'ros': 39312,\n",
       " 'premiere': 40223,\n",
       " 'segurança': 64447,\n",
       " 'marcou': 75833,\n",
       " '##孝': 113126,\n",
       " '##eken': 23653,\n",
       " '虢': 6952,\n",
       " '##уун': 95282,\n",
       " 'geleitet': 98021,\n",
       " '##बाद': 43716,\n",
       " 'μm': 89559,\n",
       " 'Gigi': 75339,\n",
       " 'теми': 79746,\n",
       " 'российский': 35413,\n",
       " '##மல்': 62466,\n",
       " 'concession': 99599,\n",
       " 'postali': 98406,\n",
       " '##стью': 35131,\n",
       " 'Kabupaten': 16842,\n",
       " '##풍': 119409,\n",
       " 'सीमा': 95425,\n",
       " 'Roku': 24522,\n",
       " 'bekerja': 35986,\n",
       " '##гло': 77162,\n",
       " 'Mawrth': 85723,\n",
       " '##輿': 117395,\n",
       " 'turned': 21031,\n",
       " '##عی': 40750,\n",
       " 'убийства': 99193,\n",
       " '##guda': 47674,\n",
       " '##吁': 112532,\n",
       " 'Monumento': 78608,\n",
       " 'ask': 63001,\n",
       " 'getötet': 68983,\n",
       " 'valamint': 19529,\n",
       " 'இருந்தது': 59590,\n",
       " '##erici': 97128,\n",
       " '##čius': 38140,\n",
       " 'rugsėjo': 59838,\n",
       " 'ラ': 2056,\n",
       " 'katonai': 51209,\n",
       " '##ಕೀಯ': 77561,\n",
       " '##علاقة': 108141,\n",
       " '羿': 6434,\n",
       " 'última': 16077,\n",
       " 'Nürnberg': 30551,\n",
       " 'scoring': 27346,\n",
       " '##ਤੀ': 33021,\n",
       " 'Abschluss': 34419,\n",
       " 'millî': 51597,\n",
       " '##muth': 95963,\n",
       " 'ésser': 99211,\n",
       " 'вид': 16133,\n",
       " '1690': 34881,\n",
       " '##שבה': 84179,\n",
       " 'zbyt': 92552,\n",
       " 'درجة': 37970,\n",
       " '##րանի': 66993,\n",
       " '消': 5010,\n",
       " 'זו': 15012,\n",
       " '##mai': 23611,\n",
       " 'kutoka': 33376,\n",
       " '##финале': 86133,\n",
       " 'koe': 93767,\n",
       " '##涛': 114783,\n",
       " '##잇': 119191,\n",
       " '##рс': 45760,\n",
       " 'ACT': 90119,\n",
       " 'całkowicie': 75822,\n",
       " 'विधानसभा': 82830,\n",
       " 'Államok': 88189,\n",
       " 'mưu': 72656,\n",
       " 'roughly': 40540,\n",
       " 'dernières': 41545,\n",
       " 'خلال': 15435,\n",
       " 'Arlington': 67799,\n",
       " 'courant': 39885,\n",
       " 'erweiterte': 99537,\n",
       " '##屎': 113258,\n",
       " '##煉': 115091,\n",
       " '##యారు': 98646,\n",
       " 'хӀаваан': 32587,\n",
       " 'sports': 18204,\n",
       " '##pse': 39568,\n",
       " 'estremamente': 90191,\n",
       " 'şair': 106243,\n",
       " 'אביב': 21425,\n",
       " '##クト': 105422,\n",
       " '##kým': 30145,\n",
       " 'צבא': 56750,\n",
       " '##ρικά': 43117,\n",
       " '##chodzi': 61062,\n",
       " 'Місто': 99740,\n",
       " '##ебе': 100320,\n",
       " 'rate': 18344,\n",
       " 'hår': 109723,\n",
       " 'Changes': 79635,\n",
       " 'VW': 108027,\n",
       " 'aid': 19778,\n",
       " '##直': 115525,\n",
       " 'ਰ': 1041,\n",
       " 'producto': 51033,\n",
       " '##רע': 93796,\n",
       " '##യുന്നത്': 105516,\n",
       " 'doby': 33530,\n",
       " 'Pilar': 47471,\n",
       " '##ೀನ': 92151,\n",
       " '##маль': 91691,\n",
       " 'Samara': 99536,\n",
       " 'État': 15429,\n",
       " 'spoke': 50005,\n",
       " 'இரண்டாம்': 76903,\n",
       " 'Известия': 108046,\n",
       " '##еж': 49867,\n",
       " 'exilio': 94414,\n",
       " '##ческую': 34473,\n",
       " 'production': 12116,\n",
       " 'شش': 89057,\n",
       " 'administrazio': 51093,\n",
       " '##ведение': 47154,\n",
       " '梗': 4610,\n",
       " 'Sociales': 110455,\n",
       " 'ฉ': 1401,\n",
       " 'skreiv': 91750,\n",
       " '##ہر': 52437,\n",
       " '룬': 9215,\n",
       " '##zato': 48180,\n",
       " '##笥': 115826,\n",
       " 'objectives': 99570,\n",
       " 'Guerre': 19022,\n",
       " '喉': 2914,\n",
       " 'berhasil': 35406,\n",
       " '##白': 115481,\n",
       " '嘘': 2951,\n",
       " '2540': 94048,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EbbyIxRcIwzx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "tokenizer를 이용해서 한국어 문장을 tokenization을 해보겠습니다.\n",
    "\n",
    "1. tokenizer를 call하는 방식\n",
    "2. tokenize()\n",
    "3. encode()\n",
    "\n",
    "\n",
    "첫번째로, tokenizer를 call하는 방식을 이용해 tokenization을 진행해보겠습니다.\n",
    "\n",
    "tokenizer를 call하는 방식을 이용하면 주어진 text를 tokenization한 뒤 model 입력에 필요한 모든 요소를 반환해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9NNsJMkJTKc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "text = '이순신은 조선 중기의 무신이다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1661316113280,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "hu6Vomw4IkeG",
    "outputId": "9da34169-60cf-4044-a39b-07b3d5e1fe36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# 1. tokenizer를 call하는 방식\n",
    "\n",
    "tokenized_text = tokenizer(text)\n",
    "\n",
    "print(tokenized_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQGnVAteKD-n",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "input_ids, token_type_ids, attention_mask가 반환된 것을 볼 수 있습니다.\n",
    "\n",
    "다운로드 받은 tokenizer가 BERT 모델을 위한 tokenizer이기 때문에 🤗 Transformers에 정의된 BERT architecture가 요구하는 입력 형태인 input_ids, token_type_ids, attention_mask로 맞추어 반환한 것을 확인할 수 있습니다.\n",
    "\n",
    "간단하게 각각의 역할에 대해 설명하면,\n",
    "* input_ids: tokenized된 text에 앞 뒤로 special token을 추가한뒤 id값으로 변형한 값을 뜻합니다.\n",
    "* token_type_ids: BERT의 segment embedding을 뜻합니다. 현재 문장이 1개가 들어왔기 때문에 token_type_ids가 모두 0인 것을 확인할 수 있습니다.\n",
    "* attention_mask: pad token은 0으로 나머지 token들은 1을 가집니다. attention 계산을 위해 불필요한 값들을 masking 처리한다고 보면 됩니다.\n",
    "\n",
    "반환된 값을 그대로 model의 입력에 넣어주면 됩니다.\n",
    "\n",
    "두번째로, tokenize()를 이용하여 tokenization하는 방법입니다.\n",
    "\n",
    "tokenize() 메소드는 주어진 text를 단순히 tokenization만 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1661316784633,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "GFvmbYy0J_rY",
    "outputId": "c641989a-01ba-4b38-eb72-2820f59e1c2b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFbrhDj0MoJw",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "이순신은 조선 중기의 무신이다. → ['이', '##순', '##신', '##은', '조선', '중', '##기의', '무', '##신', '##이다', '.']로 tokenization된 것을 확인할 수 있습니다.\n",
    "\n",
    "세번째로, encode()를 이용하는 방법입니다.\n",
    "\n",
    "encode()는 tokenized된 text에 앞 뒤로 special token을 추가한뒤 id값으로 바꿉니다.\n",
    "input_ids와 동일합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1661317430442,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "JVD54aYMMl7L",
    "outputId": "287ef5fc-2180-469f-dc8c-b5fc7f072b24",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qdmudkiPhZ1",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "input_ids와, encode()의 반환값을 모두 decode()를 이용하여 원래 문장으로 다시 변환할 수 있습니다.\n",
    "\n",
    "앞 뒤에 [CLS], [SEP] token이 붙은 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1661317722368,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "ioXAY7DYPDY0",
    "outputId": "886c697e-fb1f-4857-b288-029f8bcc7d83",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102]\n",
      "[CLS] 이순신은 조선 중기의 무신이다. [SEP]\n",
      "[101, 9638, 119064, 25387, 10892, 59906, 9694, 46874, 9294, 25387, 11925, 119, 102]\n",
      "[CLS] 이순신은 조선 중기의 무신이다. [SEP]\n"
     ]
    }
   ],
   "source": [
    "tokenized_text1 = tokenizer(text)\n",
    "print(tokenized_text1['input_ids'])\n",
    "print(tokenizer.decode(tokenized_text1['input_ids']))\n",
    "\n",
    "tokenizer_text2 = tokenizer.encode(text)\n",
    "print(tokenizer_text2)\n",
    "print(tokenizer.decode(tokenizer_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_I8LwdOQo9H",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## AutoModel\n",
    "\n",
    "AutoModel을 이용하여 base model을 load할 수 있습니다.\n",
    "* base model이라 함은 task를 위한 classifier등이 부착되지 않은 vanilla 형태를 가리킵니다.\n",
    "* AutoModel을 이용해 task를 수행하기 위해서는 별도의 classifier등을 부착해야합니다.\n",
    "\n",
    "🤗 Transformers에서는 다양한 task들에 적합한 model archtecture를 이미 AutoClass 형태로 제공하고 있습니다. 예를 들어 AutoModelForMaskedLM은 masked langunage modeling을 위한 AutoClass입니다.\n",
    "* AutoClass 목록은 [여기](https://huggingface.co/docs/transformers/model_doc/auto#auto-classes)서 확인할 수 있습니다.\n",
    "* AutoModelForQuestionAnswering\n",
    "* AutoModelForSequenceClassification\n",
    "* AutoModelForTokenClassification\n",
    "\n",
    "\n",
    "'bert-base-multilingual-cased'의 base model과 Token Classification model을 load하여 형태가 어떻게 다른지 확인해보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fj5KUd2BP6GX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bert-base-multilingual-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6614,
     "status": "ok",
     "timestamp": 1661318403619,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "SAbgH3OVSWhh",
    "outputId": "ca5810d2-20f8-41bf-b5a5-f07e4b742134",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoModelForTokenClassification\n",
    "\n",
    "base_model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "token_class_model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1661318412687,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "Pl64Hcr9SjFz",
    "outputId": "69d87c28-605c-40d8-fddc-f6bf2b5296e5",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1661318426955,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "CpI8auEeSzQf",
    "outputId": "187fdab3-5323-45b5-d51e-723e6dd188c3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_class_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUXezdAMS_KQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Token Classification model에는 pooler 대신 classifier가 추가된 것을 확인할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPd/lNumDCyWyRnv9B+q4e4",
   "collapsed_sections": [],
   "name": "tutorial2_load_pretrained_instances_with_an_AutoClassipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}