{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfSdpbsxsGCu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pipelines for inference\n",
    "\n",
    "※ 이 글의 원문은 [이 곳](https://huggingface.co/docs/transformers/pipeline_tutorial)에서 확인할 수 있습니다. (모든 글의 내용을 포함하지 않으며 새롭게 구성한 내용도 포함되어 있습니다.)\n",
    "\n",
    "[pipeline()](https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/pipelines#pipelines) 함수를 이용해 모델의 구조를 정확히 모르더라도 pretrained 모델을 이용해 자연어처리 task를 수행할 수 있습니다.\n",
    "* [pipeline()을 이용해 수행할 수 있는 task](https://huggingface.co/docs/transformers/v4.21.1/en/main_classes/pipelines#transformers.pipeline.task)\n",
    "    * text-classification\n",
    "    * text-generation\n",
    "    * token-classification\n",
    "    * fill-mask\n",
    "\n",
    "[Model Hub](https://huggingface.co/models)에서 pretrained model들을 확인해볼 수 있습니다. 각 모델별로 수행할 수 있는 task가 모두 다르므로 task에 적합한 모델을 찾아야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvMyXNrv5fy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## pipeline()을 이용해 fill-mask task 수행하기\n",
    "\n",
    "task에 적합한 model을 찾았다면 AutoModel, AutoTokenizer 클래스를 이용하여 model과 model에 사용되는 tokenizer를 간단하게 다운로드할 수 있습니다.\n",
    "* AutoClass에 관해서는 다음 글에서 다룹니다.\n",
    "* 이번에는 fill-mask를 수행하기 때문에 AutoModelForMaskedLM 클래스를 이용하여 모델을 불러옵니다. (AutoModel을 이용할 경우 에러가 발생합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13438,
     "status": "ok",
     "timestamp": 1661259378415,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "Dz7dM-ASr15p",
    "outputId": "3bb83ccb-3a19-4b6f-8563-b185c02eb53e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4NQaa_sxiVH",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "한국어 fill-mask task를 수행하기위해 BERT pretrained 모델 중에서 [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)를 불러옵니다.\n",
    "* 다양한 언어를 다룰 수 있는 multilingual model입니다.\n",
    "\n",
    "from_pretrained()에 model 이름을 넣으면 손쉽게 pretrained model, tokenizer를 불러올 수 있습니다.\n",
    "\n",
    "* 일반적으로 model에 사용되는 configuration, tokenizer가 모두 다르기 때문에 사용하려는 model에 적합한 configuration, tokenizer를 불러와야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7826,
     "status": "ok",
     "timestamp": 1661260576592,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "AXW1NrxcxhmW",
    "outputId": "aae072bd-ef73-467e-be26-09008aff57dc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lqYDspzzeW6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "먼저 tokenizer가 정상적으로 동작하는지 확인합니다.\n",
    "* 원문: 이순신은 조선 중기의 무신이다.\n",
    "* mask: 이순신은 [MASK] 중기의 무신이다.\n",
    "\n",
    "fill-mask task를 수행하려면 text내에 [MASK] special token이 포함되어 있어야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1661260604738,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "3pOfGHfWygsu",
    "outputId": "4a5b03a1-4742-49e4-a7b6-df38e5ac8dab",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '##순', '##신', '##은', '[MASK]', '중', '##기의', '무', '##신', '##이다', '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"이순신은 [MASK] 중기의 무신이다.\"\n",
    "\n",
    "tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsMBSEbZ0KkK",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "BERT는 WordPiece 방식의 tokenization을 사용하기 때문에 ##이라는 특별한 prefix가 붙어있는 token들을 확인할 수 있습니다.\n",
    "* ##은 해당 token이 원래는 앞 token과 붙어있다는 것을 의미합니다. e.g.) 이순신 → 이, ##순, ##신\n",
    "\n",
    "pipeline()을 이용해 한국어 fill-mask task를 수행하기위한 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_PLg080i0FOa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "kor_mask_fill = pipeline(task='fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpPDKCa_1SYX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "kor_mask_fill 함수를 이용하여 fill-mask task를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1661260610581,
     "user": {
      "displayName": "노건웅",
      "userId": "15551531149853643978"
     },
     "user_tz": -540
    },
    "id": "YsvEQn5T093I",
    "outputId": "cde66870-b81d-4e7d-a449-4f9d162cb7d3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.874712347984314,\n",
       "  'token': 59906,\n",
       "  'token_str': '조선',\n",
       "  'sequence': '이순신은 조선 중기의 무신이다.'},\n",
       " {'score': 0.0643644854426384,\n",
       "  'token': 9751,\n",
       "  'token_str': '청',\n",
       "  'sequence': '이순신은 청 중기의 무신이다.'},\n",
       " {'score': 0.010954903438687325,\n",
       "  'token': 9665,\n",
       "  'token_str': '전',\n",
       "  'sequence': '이순신은 전 중기의 무신이다.'},\n",
       " {'score': 0.004647187888622284,\n",
       "  'token': 22200,\n",
       "  'token_str': '##종',\n",
       "  'sequence': '이순신은종 중기의 무신이다.'},\n",
       " {'score': 0.0036106701008975506,\n",
       "  'token': 12310,\n",
       "  'token_str': '##기',\n",
       "  'sequence': '이순신은기 중기의 무신이다.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"이순신은 [MASK] 중기의 무신이다.\"\n",
    "\n",
    "kor_mask_fill(\"이순신은 [MASK] 중기의 무신이다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRYUViBy25ld",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "[MASK] 자리에 들어갈 token들을 리스트 형태로 반환합니다.\n",
    "* score: 점수\n",
    "* token: token id\n",
    "* token_str: token text"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnTiHFQU2jSf+YZxvPpTg1",
   "collapsed_sections": [],
   "name": "tutorial1_pipelines_for_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}